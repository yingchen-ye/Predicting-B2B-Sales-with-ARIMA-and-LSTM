{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "import feature_engine\n",
    "import statsmodels\n",
    "import pmdarima\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset Cleaning\n",
    "\n",
    "In this section, the raw dataset is cleaned: 1) Deleted the renewal business by filtering out the TCV of 0 and NA; 2) Stripe the Year, Quarter, Month, Week, and transform them to numeric values; 3) Based on the time information, create a new column \"Week\" that indicates which week the record belongs to in the 6 fiscal years.\n",
    "\n",
    "* The \"Week\" column and the TCV are saved in a single dataset for the following data preprocessing.\n",
    "* After subsetting from the raw dataset, there are no missing data in the columns that are of the thesis's concern.\n",
    "* Note: Now I will only use the overall sum. In the future, I will include the categorical data: the product information and geographical inforamtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FY17_22 = pd.read_csv(\"./data/Raw data FY17-22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FY17_22.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_needed_col = FY17_22.loc[:,['ENTArea','ENTRegion','ENTDistrict',\n",
    "                   'ProductSegment','ProductPlatform','ProductSuite', 'ProductSolution',\n",
    "                   'CloseDate','FiscalYear','FiscalQuarter','FiscalWeek',\n",
    "                   'LineItemNetNewTCV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_needed_col.columns = ['ENT Area','ENT Region','ENT District',\n",
    "                   'Product Segment','Product Platform','Product Suite', 'Product Solution',\n",
    "                   'Close Date','Fiscal Year','Fiscal Quarter','Fiscal Week',\n",
    "                   'Line Item Net New TCV']\n",
    "# data_needed_col.to_csv('./data/Raw Data with Area & Product.csv', index=None)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time date feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/Raw Data with Area & Product.csv\")\n",
    "data = data[data.iloc[:,-1]!=0]\n",
    "data = data[data['Line Item Net New TCV'].notna()]\n",
    "# data['Fiscal Year'] = data['Fiscal Year'].apply(lambda x: x.strip(\"FY\"))\n",
    "data['Fiscal Quarter'] = data['Fiscal Quarter'].apply(lambda x: x.strip(\"Q\"))\n",
    "data['Fiscal Week'] = data['Fiscal Week'].apply(lambda x: x.strip(\"W\"))\n",
    "data['Fiscal Year'], data['Fiscal Quarter'], data['Fiscal Week'] = pd.to_numeric(data['Fiscal Year']), \\\n",
    "    pd.to_numeric(data['Fiscal Quarter']), pd.to_numeric(data['Fiscal Week'])\n",
    "data['Close Date'] = pd.to_datetime(data['Close Date'])\n",
    "### week index: week 1 is 0 (to align with the prediction index)\n",
    "data['Week'] = data['Fiscal Week'] + (data['Fiscal Quarter'] - 1)*13 + (data['Fiscal Year'] -2017)*52 -1\n",
    "# data['Month'] = data['Fiscal Month In Qtr'] + (data['Fiscal Quarter'] -1 )* 3 + (data['Fiscal Year'] -2017) * 12\n",
    "data['Quarter'] = data['Fiscal Quarter'] + (data['Fiscal Year'] -2017)*4\n",
    "# data.to_csv('./data/cleaned_raw_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)\n",
    "data.info()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output of each step just in case, but I have \\\n",
    "# already saved the data and I can read it, so deactivate the selection\n",
    "\n",
    "# cleaned_raw_data = pd.read_csv('./data/cleaned_raw_data.csv')\n",
    "# weekly_data = cleaned_raw_data.loc[:,['Week', 'Line Item Net New TCV']]\n",
    "# weekly_data.to_csv('./data/weekly_raw_data.csv', index=None)\n",
    "weekly_data = pd.read_csv('./data/weekly_raw_data.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "weekly_sum = weekly_data.groupby(['Week']).sum()\n",
    "weekly_sum.info()\n",
    "# weekly_sum.to_csv('./data/weekly_sum.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# the data is cleaned now without missing data, so no need of this block\n",
    "# =============\n",
    "# there are only 310 weeks, which means two weeks are missing.\n",
    "# find the weeks and add them to the dataset\n",
    "# fill them with the mean of the dataset\n",
    "\n",
    "for i in range(1,309):\n",
    "   if weekly_sum.index[i+1]-weekly_sum.index[i] !=1:\n",
    "    print(weekly_sum.index[i]+1)\n",
    "\n",
    "# week 39 and week 299 are missing\n",
    "# FY17 Q3 W13, FY21 Q3 W13\n",
    "weekly_sum.loc[39], weekly_sum.loc[299] = weekly_sum.mean(), weekly_sum.mean()\n",
    "\n",
    "weekly_sum = weekly_sum.sort_index()\n",
    "weekly_sum.index\n",
    "weekly_sum[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection and Cleaning (Anomolies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Outlier Detection with Hampel Filter: https://towardsdatascience.com/outlier-detection-with-hampel-filter-85ddf523c73d\n",
    "* treatment: https://medium.com/wwblog/clean-up-your-time-series-data-with-a-hampel-filter-58b0bb3ebb04\n",
    "* Outlier detection is not necessary. So better skip it and focus on the LSTM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sktime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this does not have imputation\n",
    "from sktime.transformations.series.outlier_detection import HampelFilter\n",
    "\n",
    "transformer = HampelFilter(window_length=11)\n",
    "buffer = transformer.fit_transform(weekly_sum)\n",
    "buffer.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://github.com/MichaelisTrofficus/hampel_filter\n",
    "# introduction in (Bhowmlk et al, 2017)\n",
    "# imputation is moving median, it's said to be robust while moving mean is not (needs literature)\n",
    "from hampel import hampel\n",
    "\n",
    "buffer_imputation = hampel(weekly_sum, window_size = 6, n=3, imputation = True)\n",
    "weekly_sum.plot(style='k-')\n",
    "buffer_imputation.plot(style=\"g-\")\n",
    "plt.show()\n",
    "\n",
    "outlier_indices = hampel(weekly_sum, window_size=5, n=3)\n",
    "print(len(outlier_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the trend change\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "plt.figure(1)\n",
    "stl = STL(buffer_imputation, period = 52)\n",
    "STL_result = stl.fit()\n",
    "STL_result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive EDA\n",
    "\n",
    "Check the mean, range, std of the weekly sum of TCV. The std is high, indicating a high variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.read_csv('./data/weekly_sum.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "data = pd.DataFrame(series.values, index=range(0,312))\n",
    "data.columns = ['bookings']\n",
    "print(data.info(), data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for correlation and autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use plot and Peasron's correlation coefficient to check the correlation of different lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the lag of 52 weeks (1 year)\n",
    "# the correlation is obviously quarter-wise\n",
    "# 52 weeks has the highest correlation\n",
    "values = pd.DataFrame(data.values)\n",
    "for a in range(1,53):\n",
    "    dataframe = pd.concat([values.shift(a), values], axis =1)\n",
    "    dataframe.columns=['t','t+'+str(a)]\n",
    "    result = dataframe.corr()\n",
    "    if abs(result.loc['t', 't+'+str(a)]) > 0.5:\n",
    "        print(a, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "pd.plotting.lag_plot(data, lag=13)\n",
    "plt.subplot(222)\n",
    "pd.plotting.lag_plot(data, lag=26)\n",
    "plt.subplot(223)\n",
    "pd.plotting.lag_plot(data, lag=39)\n",
    "plt.subplot(224)\n",
    "pd.plotting.lag_plot(data, lag=52)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ACF and PACF plot to check the autocorrelation and partial autocorrelation (define them in the thesis)\n",
    "* The slow decrease in the ACF as the lags increase is due to the trend, while the “scalloped” shape is due the seasonality (Forecasting textbook, 2.8) \n",
    "* we will do it again with autocorrelation tests after variance stabilization to decide the hyperparameters of ARIMA\n",
    "* this is part of EDA to check the stationarity\n",
    "* Interpretation:\n",
    "(1) ACF and PACF give different results, which means the data now is not stationary (has seasonality and trend);\n",
    "(2) Our plot shows the “scalloped” shape, meaning that it has seasonality.\n",
    "(3) Can't see the trend from this plot. Need further tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a Yule-Walker without adjustment here, the \"ywm\"\n",
    "# http://www.ees.nmt.edu/outside/courses/GEOP505/Docs/pac.pdf\n",
    "# we know the autocorrelation from acf, thus we can use ywm\n",
    "# the confidence interval is 95% on default\n",
    "# http://stat.wharton.upenn.edu/~steele/Courses/956/Resource/YWSourceFiles/WhyNotToUseYW.pdf\n",
    "# this source mentioned that ym is worse than burg for AM, but I can't run burg in this package\n",
    "# besides, it's for ARIMA\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(data, lags = 52)\n",
    "plot_pacf(data, lags=52, method = 'ywm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationarity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will use ADF(Augmented Dickey-Fuller (ADF) test) to check if the data is stationary\n",
    "* both before and after the stabilization\n",
    "* p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n",
    "* p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",
    "* [result]: before stabilization, we can see that our data is very not stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series):\n",
    "\n",
    "    result = adfuller(series.values)\n",
    "\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n",
    "        print(\"\\u001b[32mStationary\\u001b[0m\")\n",
    "    else:\n",
    "        print(\"\\x1b[31mNon-stationary\\x1b[0m\")\n",
    "check_stationarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance stability\n",
    "\n",
    "* Plot to check the variance stability\n",
    "* The variance seems not stable, use log transformation to stablize the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Before Log Transformation')\n",
    "plt.plot(data)\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Net New TCV')\n",
    "\n",
    "#histogram\n",
    "plt.subplot(212)\n",
    "plt.hist(data)\n",
    "plt.xlabel('Net New TCV')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bookings'] = np.log(data['bookings'])\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.title('After Log Transformation')\n",
    "plt.plot(data)\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Net New TCV')\n",
    "\n",
    "#histogram\n",
    "plt.subplot(212)\n",
    "plt.hist(data)\n",
    "plt.xlabel('Net New TCV')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# it is a good method, but contains learnable parameters so needs to be done after splitting data\n",
    "# but I want to do feature engineering beforfe splitting. Log is simplier, the effect looks same\n",
    "\n",
    "from scipy.stats import boxcox\n",
    "# Box-Cox transformation\n",
    "# find a good lambda\n",
    "data, lam = boxcox(data)\n",
    "print(\"Lambda: %f\" % lam)\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.title('After Box-Cox Transformation')\n",
    "plt.plot(data)\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Net New TCV')\n",
    "\n",
    "#histogram\n",
    "plt.subplot(212)\n",
    "plt.hist(data)\n",
    "plt.xlabel('Net New TCV')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean stationarity\n",
    "\n",
    "* check with STL decomposition\n",
    "* differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "plt.figure(1)\n",
    "stl = STL(data, period = 52)\n",
    "STL_result = stl.fit()\n",
    "STL_result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see, there are trend and seasonality, it is time for differencing\n",
    "* d=1 cause p-value dropped under 0.05 after 1st order differencing\n",
    "* we don't need to detrend in the FE because it's intergrated in ARIMA. But we may need it for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the diff() and adfuller() to check the result of differencing\n",
    "differencing_result = adfuller(data.squeeze().diff().dropna())\n",
    "print('1st order differencing, p-value: ', differencing_result[1])\n",
    "\n",
    "differencing_result = adfuller(data.squeeze().diff().dropna())\n",
    "print('2nd order differencing, p-value: ', differencing_result[1])\n",
    "\n",
    "differencing_result = adfuller(data.squeeze().diff().dropna())\n",
    "print('* 3rd order differencing, p-value: ', differencing_result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally, after feature engineering, check the stationarity again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_stationarity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(data.squeeze().diff().dropna(), lags = 52)\n",
    "plot_pacf(data.squeeze().diff().dropna(), lags=52, method = 'ywm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the data is still not stationary, because the trend and seasonality are not removed\n",
    "* I will train ARIMA and SAMIRA, and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data for future training\n",
    "data.to_csv('./data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AM does not need stationary input, but LSTM probably need\n",
    "# do a first order differencing\n",
    "diff_data = data.squeeze().diff().dropna()\n",
    "check_stationarity(diff_data)\n",
    "\n",
    "# split the dataset\n",
    "test_size = 52\n",
    "diff_data_train, diff_data_val, diff_data_test = diff_data[ :-2*test_size], diff_data[-2*test_size:-test_size], diff_data[-test_size:]\n",
    "\n",
    "diff_train_X = diff_data_train.values\n",
    "diff_val_X  = diff_data_val.values\n",
    "diff_test_X = diff_data_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_data.plot()\n",
    "plt.title(\"After first-order differencing\")\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Net New TCV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_diff_data = diff_data.squeeze().diff(periods = 52).dropna()\n",
    "seasonal_diff_data.plot()\n",
    "plt.title(\"After seasonal differencing\")\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Net New TCV')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plot_acf(diff_data, lags = 52)\n",
    "plot_pacf(diff_data, lags=52, method = 'ywm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset split (Do it just before the model training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* split the dataset into train, (validation) and testing datasets\n",
    "* separate one quarter, 52 weeks as validation and test sets cause this is a complete period\n",
    "* below is the manual way, let's use it first to try the model training, and use walk-forward in the future with the function TimeSeriesSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/preprocessed_data.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "test_size = 52\n",
    "data_train, data_val, data_test = data[ :-2*test_size], data[-2*test_size:-test_size], data[-test_size:]\n",
    "print(data_train.shape, data_val.shape, data_test.shape)\n",
    "#data_train.to_csv(\"./data/train_data.csv\", header=None)\n",
    "#data_val.to_csv(\"./data/val_data.csv\", header=None)\n",
    "#data_val.to_csv(\"./data/testing_data.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For ARIMA, aggregate the weekly sum. separate testing dataset, then split the data with TimeSeriesSplit().\n",
    "* Because the dataset is small (312 weeks), we will use cross-validation/walk-forward validation\n",
    "* TimeSeriesSplit() has an output called \"split\", with a for loop, we can use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series split (lec 3, p. 51), here we use extending windows (vs. sliding windows)\n",
    "# literature uses extending windows cross validation: https://www.sciencedirect.com/science/article/pii/S1110016821005470\n",
    "# this chunk prepares the cross validation loop \n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# we can use the variable, weekly_sum, but I want to read from the csv file\n",
    "weekly_sum = pd.read_csv('./data/weekly_sum.csv', index_col = 0, parse_dates=True, squeeze=True)\n",
    "\n",
    "# one year is set out for both val and testing sets\n",
    "test_size = 52\n",
    "data_train_val, data_test = data[ :-test_size], data[-test_size:]\n",
    "\n",
    "# to see the splitting index\n",
    "tscv = TimeSeriesSplit(n_splits=3, test_size=test_size)\n",
    "for train_index, val_index in tscv.split(data_train_val):\n",
    "    cv_train, cv_val = data_train_val.iloc[train_index], data_train_val.iloc[val_index]\n",
    "    print(train_index, val_index)\n",
    "\n",
    "#### model training from here ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to report the result:\n",
    "def ts_report(y_true, y_pred, model, model_fit):\n",
    "    # measures on validation set\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return model_fit.aic, model_fit.hqic, model_fit.bic, rmse, mse, mae, r2, mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Training with Continuous Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* metrics should add MAPE, correlation, min-max (https://www.machinelearningplus.com/time-series/arima-model-time-series-forecasting-python/)\n",
    "* add the residual diagonistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive (AR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's numpy array, the original dataset is series with time information\n",
    "train_X = data_train.values\n",
    "val_X  = data_val.values\n",
    "test_X = data_test.values\n",
    "train_val_X = data_train_val.values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# AM does not need stationary input, but LSTM probably need\n",
    "# do a first order differencing\n",
    "diff_data = data.squeeze().diff().dropna()\n",
    "check_stationarity(diff_data)\n",
    "\n",
    "# split the dataset\n",
    "test_size = 52\n",
    "diff_data_train, diff_data_val, diff_data_test = diff_data[ :-2*test_size], diff_data[-2*test_size:-test_size], diff_data[-test_size:]\n",
    "\n",
    "diff_train_X = diff_data_train.values\n",
    "diff_val_X  = diff_data_val.values\n",
    "diff_test_X = diff_data_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's not useful\n",
    "def ts_report_print(y_true, y_pred, model, model_fit):\n",
    "    out1 = 'AIC: {0:0.3f}, HQIC: {1:0.3f}, BIC: {2:0.3f}'\n",
    "    out_print1 = out1.format(model_fit.aic, model_fit.hqic, model_fit.bic)\n",
    "    \n",
    "    # measures on validation set\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    out2 = '{0:0.3s} RMSE on validation set: {1:0.3f},\\\n",
    "            {0:0.3s} MSE on validation set: {2:0.3f},\\\n",
    "            {0:0.3s} MAE on validation set: {3:0.3f},\\\n",
    "            {0:0.3s} R-squared on validation set: {4:0.3f},\\\n",
    "            {0:0.3s} MAPE on validation set: {5:0.3f}'\n",
    "    out_print2 = out2.format(model, rmse, mse, mae, r2, mape)\n",
    "    return out_print1, out_print2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should record all the metrics in the cross validation and finally average and report them.\n",
    "AM_p = range(1, 14)\n",
    "\n",
    "AM_cv_result = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "for p in AM_p:\n",
    "    metrics = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "    for train_index, val_index in tscv.split(data_train_val):\n",
    "        cv_train, cv_val = data_train_val.iloc[train_index], data_train_val.iloc[val_index]\n",
    "        AM_model = AutoReg(cv_train, lags=p)\n",
    "        AM_fit = AM_model.fit()\n",
    "        AM_predictions = AM_fit.predict(start=len(cv_train), end=len(cv_train)+len(cv_val)-1, dynamic=False)\n",
    "        AM_predictions = pd.Series(AM_predictions, index=cv_val.index)\n",
    "        metrics.loc[len(metrics)] = list(ts_report(cv_val, AM_predictions, model = 'AM', model_fit=AM_fit))\n",
    "    AM_cv_result.loc[str('AM')+ str(p)]  = list(metrics.mean())\n",
    "AM_cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train AM(13) because it's the best\n",
    "#  on 5-year data, and plot it\n",
    "AM_result = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "\n",
    "AM_model = AutoReg(train_val_X, lags=13)\n",
    "AM_model_fit = AM_model.fit()\n",
    "print('Coefficients: %s' % AM_model_fit.params)\n",
    "\n",
    "# measures on validation set\n",
    "AM_predictions = AM_model_fit.predict(start=len(train_val_X), end=len(train_val_X)+len(test_X)-1, dynamic=False)\n",
    "AM_predictions = pd.Series(AM_predictions, index=data_test.index)\n",
    "AM_result.loc[len(AM_result)] = list(ts_report(test_X, AM_predictions, model = 'AM', model_fit=AM_model_fit))\n",
    "\n",
    "# plot results\n",
    "plt.figure()\n",
    "plt.plot(data_test, \".-\", label=\"X_true\")\n",
    "plt.plot(AM_predictions, \"--\", label=\"X_pred\")\n",
    "plt.legend()\n",
    "plt.title('AR(13) Forecast')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bookings')\n",
    "plt.show()\n",
    "\n",
    "AM_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "# df should be h-K, where h is the maximum lags\n",
    "acorr_ljungbox(AM_model_fit.resid, lags=52)\n",
    "\n",
    "# check lags = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import jarque_bera\n",
    "jarque_bera(AM_model_fit.resid)\n",
    "# statistics, p value, skewness, kurtosis\n",
    "# p i< 0.05, reject the h0 of non-normal distribution. I.e., the residuals are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(AM_model_fit.resid, label=\"AM(13)\")\n",
    "plt.title('The Residuals of AR(13)')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residuals')\n",
    "plt.yticks(np.arange(-2.5, 17.5, step=2.5))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "stats.probplot(AM_model_fit.resid, dist = 'norm', plot =plt)\n",
    "plt.title('QQ-Plot of AR(13) Residuals')\n",
    "plt.yticks(np.arange(-2.5, 17.5, step=2.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* below is a manual way for ARIMA, but there is a function that combines the ARIMA and SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from pmdarima.arima import auto_arima\n",
    "# laji!!! tamade, didn't work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import warnings\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train each model on three different dataset, calculate the average, record the average for all the models, and finally choose the best model\n",
    "p_values = [13,26,39,52]\n",
    "d = 1\n",
    "q_values = range(0,14)\n",
    "\n",
    "ARIMA_cv_result = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "for p in p_values:\n",
    "    for q in q_values:\n",
    "        metrics = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "        arima_order = (p, d, q)\n",
    "        for train_index, val_index in tscv.split(data_train_val):\n",
    "            try:\n",
    "                cv_train, cv_val = data_train_val.iloc[train_index], data_train_val.iloc[val_index]\n",
    "                arima_model = statsmodels.tsa.arima.model.ARIMA(endog = cv_train, order = arima_order)\n",
    "                arima_fit = arima_model.fit()\n",
    "                arima_forcast = pd.Series(arima_fit.predict(start = len(cv_train), end=len(cv_train)+ len(cv_val)-1, dynamic = False))\n",
    "                arima_forcast = arima_forcast.set_axis(cv_val.index)\n",
    "                metrics.loc[len(metrics)] = list(ts_report(cv_val, arima_forcast, model = 'ARIMA', model_fit=arima_fit))\n",
    "            except:\n",
    "                continue\n",
    "        ARIMA_cv_result.loc[str('ARIMA')+ str(arima_order)]  = list(metrics.mean())\n",
    "ARIMA_cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the 5 best models on each metrics, choose the unique orders.\n",
    "# Use them to train on the 4 years data and select the best model\n",
    "# ARIMA_cv_result.idxmin()\n",
    "ARIMA_cv_best_orders = np.array([])\n",
    "for i in ['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape']:\n",
    "    index = ARIMA_cv_result.nsmallest(5, i).index\n",
    "    print(i, index)\n",
    "    ARIMA_cv_best_orders = np.append(ARIMA_cv_best_orders, index)\n",
    "ARIMA_cv_best_orders = np.unique(ARIMA_cv_best_orders).astype(np.str)\n",
    "ARIMA_cv_best_orders = np.char.strip(ARIMA_cv_best_orders, 'ARIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_cv_best_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_cv_best_orders = np.array(['(13, 0, 0)', '(13, 0, 1)', '(13, 1, 0)', '(13, 1, 1)',\n",
    "       '(13, 1, 2)', '(13, 1, 3)', '(13, 1, 4)', '(13, 1, 5)',\n",
    "       '(13, 1, 6)', '(13, 1, 7)', '(13, 1, 8)', '(13, 1, 9)',\n",
    "       '(13, 2, 0)', '(26, 1, 0)', '(26, 1, 1)', '(26, 1, 2)',\n",
    "       '(52, 2, 11)', '(52, 2, 12)', '(52, 2, 13)', '(52, 2, 8)'],\n",
    "      dtype='<U16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just look at the ARIMA(13, 1, 0), AND the result being reported should be the aggregated metrics from cross validation\n",
    "ARIMA_result = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "for order in ARIMA_cv_best_orders:\n",
    "    arima_model = statsmodels.tsa.arima.model.ARIMA(endog = train_val_X, order = eval(order))\n",
    "    arima_fit = arima_model.fit()\n",
    "    arima_forcast = pd.Series(arima_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "    arima_forcast = arima_forcast.set_axis(data_val.index)\n",
    "    ARIMA_result.loc[str('ARIMA')+ str(order)]  = list(ts_report(test_X, arima_forcast, model = 'ARIMA', model_fit=arima_fit))\n",
    "ARIMA_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_result.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* the cross validation helps to select the best model, in our case, (13, 1, 0) or (13, 1, 6). We can report them now (also compared with the out-of sample cross-validation performance). We evaluate the model on the 4 year data to get the residuals information.\n",
    "\n",
    "* From the result of the training on 4 year data, we can see (13,1,0) has the best performance on AIC, HQIC, BIC. (13,1,0) also get the best scores from the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the result of ARIMA(13, 1, 0)\n",
    "import scipy.stats as stats\n",
    "\n",
    "best_cfg = (13, 1, 0)\n",
    "best_ARIMA = ARIMA(train_val_X, order = best_cfg)\n",
    "best_ARIMA_fit = best_ARIMA.fit()\n",
    "plt.figure()\n",
    "plt.plot(best_ARIMA_fit.resid, label=\"{}\".format(best_cfg))\n",
    "plt.title('The Residuals of ARIMA{}'.format(best_cfg))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "stats.probplot(best_ARIMA_fit.resid, dist = 'norm', plot =plt)\n",
    "plt.title('QQ-Plot of ARIMA{} Residuals'.format(best_cfg))\n",
    "plt.show()\n",
    "\n",
    "best_ARIMA_predictions = pd.Series(best_ARIMA_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_ARIMA_predictions = best_ARIMA_predictions.set_axis(data_test.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, \".-\", label=\"X_true\")\n",
    "plt.plot(best_ARIMA_predictions, \"--\", label=\"X_pred\")\n",
    "plt.legend()\n",
    "plt.title('ARIMA{} Forecast'.format(best_cfg))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bookings')\n",
    "plt.show()\n",
    "\n",
    "best_ARIMA_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the result of ARIMA(13, 1, 6)\n",
    "import scipy.stats as stats\n",
    "\n",
    "best_cfg = (13, 1, 6)\n",
    "best_ARIMA = ARIMA(train_val_X, order = best_cfg)\n",
    "best_ARIMA_fit = best_ARIMA.fit()\n",
    "plt.figure()\n",
    "plt.plot(best_ARIMA_fit.resid, label=\"{}\".format(best_cfg))\n",
    "plt.title('The Residuals of ARIMA{}'.format(best_cfg))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "stats.probplot(best_ARIMA_fit.resid, dist = 'norm', plot =plt)\n",
    "plt.title('QQ-Plot of ARIMA{} Residuals'.format(best_cfg))\n",
    "plt.show()\n",
    "\n",
    "best_ARIMA_predictions = pd.Series(best_ARIMA_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_ARIMA_predictions = best_ARIMA_predictions.set_axis(data_test.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, \".-\", label=\"X_true\")\n",
    "plt.plot(best_ARIMA_predictions, \"--\", label=\"X_pred\")\n",
    "plt.legend()\n",
    "plt.title('ARIMA{} Forecast'.format(best_cfg))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bookings')\n",
    "plt.show()\n",
    "\n",
    "best_ARIMA_fit.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from traceback import print_tb\n",
    "import warnings\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "p_values = [13,26,39,52]\n",
    "d_values = range(0,3)\n",
    "q_values = range(0,14)   # the adfuller shows the cyclity around 4, let me try one quarter\n",
    "\n",
    "best_score, best_cfg = float(\"inf\"), None\n",
    "\n",
    "for p in p_values:\n",
    "    for d in d_values:\n",
    "        for q in q_values:\n",
    "            arima_order = (p, d, q)\n",
    "            try:\n",
    "                baseline_ARIMA = ARIMA(train_X, order = arima_order)\n",
    "                baseline_ARIMA_fit = baseline_ARIMA.fit()\n",
    "                predictions = baseline_ARIMA_fit.predict(start = len(train_X), end=len(train_X)+ len(val_X)-1, dynamic = False)\n",
    "                rmse = np.sqrt(mean_squared_error(val_X, predictions))\n",
    "                if rmse < best_score:\n",
    "                    best_score, best_cfg=rmse, arima_order\n",
    "                    print(\"ARIMA%s RMSE= %.3f\" % (arima_order, rmse))\n",
    "            except:\n",
    "                continue\n",
    "print(\"Best ARIMA%s RMSE= %.3f\" % (best_cfg, best_score))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# to avoid run again, let me write the paramters down:\n",
    "# best_score, best_cfg= 0.405, (52, 2, 7)\n",
    "# -------------------------------------------------\n",
    "# use the best model and plot it\n",
    "# attention!!! the index of prediction is different from the data's index\n",
    "best_baseline_ARIMA = ARIMA(data_train, order = best_cfg)\n",
    "best_baseline_ARIMA_fit = best_baseline_ARIMA.fit()\n",
    "print(best_baseline_ARIMA_fit.summary)\n",
    "plt.figure()\n",
    "plt.plot(best_baseline_ARIMA_fit.resid, label=\"{}\".format(best_cfg))\n",
    "plt.title('The Residuals from best ARIMA model')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "best_ARIMA_predictions = best_baseline_ARIMA_fit.predict(start = len(train_X), end=len(train_X)+ len(val_X)-1, dynamic = False)\n",
    "best_ARIMA_predictions = best_ARIMA_predictions.set_axis(data_val.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_val, \".-\", label=\"X_true\")\n",
    "plt.plot(best_ARIMA_predictions, \"--\", label=\"X_pred\")\n",
    "plt.legend()\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bookings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* it looks not quite right, might because of the seasonality.\n",
    "* ---- we try the seasonal ARIMA with auto.arima after this expired chunk ----\n",
    "* let's try SARIMA\n",
    "* P: Seasonal autoregressive order.\n",
    "* D: Seasonal differencing order.\n",
    "* Q: Seasonal moving average order\n",
    "* S: Length of the seasonal cycle.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is impossible to do the grid search, so I will:\n",
    "* https://jadsmkbdatalab.nl/forecasting-with-sarimax-models/\n",
    "* https://towardsdatascience.com/time-series-forecasting-with-a-sarima-model-db051b7ae459#:~:text=SARIMA%20Model%20Parameters%20%E2%80%94%20ACF%20and%20PACF%20Plots&text=p%20and%20seasonal%20P%3A%20indicate,lags%20of%20the%20forecast%20errors here use the aggregated MAPE as the objective\n",
    "* use the links to check how to illustrate the hyperparameters\n",
    "* as it is computationally expensive, I train on 4 year to get the best 10 orders to narrow dowm the range and use cross-validation to get the aggregated metrics and decide the best order\n",
    "* train on the 4 year to get the performance of the residuals (SARIMA takes care of the seasonal part, so the residuals should be less possible to be autocorrelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get the best orders\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "arima_model = auto_arima(train_X, start_p=0, d=1, start_q=0, max_p=13, max_q= 13,\n",
    "                         D=0, start_P=0, start_Q=0, max_P= 13, max_Q=13, m=52,\n",
    "                         seasonal=True, random_state=20, return_valid_fits=True,\n",
    "                         trace=1, error_action='trace', out_of_sample_size=52, scoring = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sarima_orders = pd.read_csv('./sarima_result.csv')\n",
    "# sarima_orders.nsmallest(20, 'AIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the best 20 models with lowest AIC. manually type all the orders. We will use them to do the cross validation and select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sarima_orders = np.array([\n",
    "      ['(3, 1, 1)', '(4, 0, 0, 52)'],\n",
    "      ['(3, 1, 1)', '(3, 0, 0, 52)'],\n",
    "      ['(3, 1, 1)', '(2, 0, 0, 52)'],\n",
    "      ['(3, 1, 1)', '(5, 0, 0, 52)'],\n",
    "      ['(3, 1, 2)', '(3, 0, 0, 52)'],\n",
    "      ['(3, 1, 1)', '(5, 0, 1, 52)'],\n",
    "      ['(3, 1, 1)', '(4, 0, 1, 52)'],\n",
    "      ['(3, 1, 1)', '(3, 0, 1, 52)'],\n",
    "      ['(3, 1, 1)', '(2, 0, 1, 52)'],\n",
    "      ['(3, 1, 2)', '(2, 0, 0, 52)'],\n",
    "      ['(4, 1, 1)', '(4, 0, 0, 52)'],\n",
    "      ['(4, 1, 1)', '(3, 0, 0, 52)'],\n",
    "      ['(4, 1, 1)', '(2, 0, 0, 52)'],\n",
    "      ['(4, 1, 1)', '(3, 0, 1, 52)'],\n",
    "      ['(4, 1, 2)', '(4, 0, 0, 52)'],\n",
    "      ['(2, 1, 2)', '(2, 0, 0, 52)'],\n",
    "      ['(2, 1, 1)', '(2, 0, 0, 52)']\n",
    "], dtype='<U16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMA_cv_result = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "for i in best_sarima_orders:\n",
    "    metrics = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "    for train_index, val_index in tscv.split(data_train_val):\n",
    "        cv_train, cv_val = data_train_val.iloc[train_index], data_train_val.iloc[val_index]\n",
    "        sarima_model = SARIMAX(endog = cv_train, order = eval(i[0]), seasonal_order = eval(i[1]))\n",
    "        sarima_fit = sarima_model.fit()\n",
    "        sarima_forcast = pd.Series(sarima_fit.predict(start = len(cv_train), end=len(cv_train)+ len(cv_val)-1, dynamic = False))\n",
    "        sarima_forcast = sarima_forcast.set_axis(cv_val.index)\n",
    "        metrics.loc[len(metrics)] = list(ts_report(cv_val, sarima_forcast, model = 'SARIMA', model_fit=sarima_fit))\n",
    "    SARIMA_cv_result.loc[str('ARIMA')+ str(i[0])+str(i[1])]  = list(metrics.mean())\n",
    "SARIMA_cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best order from the cross validation\n",
    "SARIMA_cv_best_orders = np.array([])\n",
    "for i in ['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape']:\n",
    "    index = SARIMA_cv_result.nsmallest(5, i).index\n",
    "    print(i, index)\n",
    "    SARIMA_cv_best_orders = np.append(SARIMA_cv_best_orders, index)\n",
    "SARIMA_cv_best_orders = np.unique(SARIMA_cv_best_orders).astype(np.str)\n",
    "SARIMA_cv_best_orders = np.char.strip(SARIMA_cv_best_orders, 'ARIMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMA_cv_best_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best model from the cross validation. It is \n",
    "SARIMA_cv_result.idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best model I decide will be ARIMA(3, 1, 2)(3,0,0,52) as it has the lowest rmse and mape, its AIC, BIC, HQIC are within the 5th lowest ones\n",
    "#  or ARIMA(2,1,1)(2,0,0,52) as it has the lowest HQIC, BIC, mae is = 0.001 from the lowest one, the mape difference is < 0.001 with 31230052.\n",
    "# Their AIC, BIC, HQIC are in the \n",
    "# train on the 5 year data to check the residuals\n",
    "final_sarima_orders = np.array([\n",
    "      ['(3, 1, 2)', '(3, 0, 0, 52)'],\n",
    "      ['(2, 1, 1)', '(2, 0, 0, 52)']\n",
    "], dtype='<U16')\n",
    "\n",
    "SARIMA_result = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "for i in final_sarima_orders:\n",
    "    metrics = pd.DataFrame(columns=['AIC', 'HQIC', 'BIC','rmse', 'mse', 'mae', 'r2', 'mape'])\n",
    "    sarima_model = SARIMAX(endog = train_val_X, order = eval(i[0]), seasonal_order = eval(i[1]))\n",
    "    sarima_fit = sarima_model.fit()\n",
    "    sarima_forcast = pd.Series(sarima_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "    sarima_forcast = sarima_forcast.set_axis(data_test.index)\n",
    "    metrics.loc[len(metrics)] = list(ts_report(test_X, sarima_forcast, model = 'SARIMA', model_fit=sarima_fit))\n",
    "    SARIMA_result.loc[str('ARIMA')+ str(i[0])+str(i[1])]  = list(metrics.mean())\n",
    "SARIMA_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the result of ARIMA(3, 1, 2)(3, 0, 0, 52)\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "best_cfg = np.array(['(3, 1, 2)', '(3, 0, 0, 52)'], dtype='<U16')\n",
    "best_SARIMA = SARIMAX(endog = train_val_X, order = eval(best_cfg[0]), seasonal_order = eval(best_cfg[1]))\n",
    "best_SARIMA_fit = best_SARIMA.fit()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(best_SARIMA_fit.resid, label=\"{}\".format(best_cfg[0] + best_cfg[1]))\n",
    "plt.title('The Residuals of ARIMA{}'.format(best_cfg[0] + best_cfg[1]))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "stats.probplot(best_SARIMA_fit.resid, dist = 'norm', plot =plt)\n",
    "plt.title('QQ-Plot of ARIMA{} Residuals'.format(best_cfg[0] + best_cfg[1]))\n",
    "plt.show()\n",
    "\n",
    "best_SARIMA_predictions = pd.Series(best_SARIMA_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_SARIMA_predictions = best_SARIMA_predictions.set_axis(data_test.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, \".-\", label=\"X_true\")\n",
    "plt.plot(best_SARIMA_predictions, \"--\", label=\"X_pred\")\n",
    "plt.legend()\n",
    "plt.title('Seasonal ARIMA{} Forecast'.format(best_cfg[0] + best_cfg[1]))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bookings')\n",
    "plt.show()\n",
    "\n",
    "best_SARIMA_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the result of ARIMA(2, 1, 1)(2, 0, 0, 52)\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "best_cfg = np.array(['(2, 1, 1)', '(2, 0, 0, 52)'], dtype='<U16')\n",
    "best_SARIMA = SARIMAX(endog = train_val_X, order = eval(best_cfg[0]), seasonal_order = eval(best_cfg[1]))\n",
    "best_SARIMA_fit = best_SARIMA.fit()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(best_SARIMA_fit.resid, label=\"{}\".format(best_cfg[0] + best_cfg[1]))\n",
    "plt.title('The Residuals of ARIMA{}'.format(best_cfg[0] + best_cfg[1]))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "stats.probplot(best_SARIMA_fit.resid, dist = 'norm', plot =plt)\n",
    "plt.title('QQ-Plot of ARIMA{} Residuals'.format(best_cfg[0] + best_cfg[1]))\n",
    "plt.show()\n",
    "\n",
    "best_SARIMA_predictions = pd.Series(best_SARIMA_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_SARIMA_predictions = best_SARIMA_predictions.set_axis(data_test.index)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, \".-\", label=\"X_true\")\n",
    "plt.plot(best_SARIMA_predictions, \"--\", label=\"X_pred\")\n",
    "plt.legend()\n",
    "plt.title('Seasonal ARIMA{} Forecast'.format(best_cfg[0] + best_cfg[1]))\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Bookings')\n",
    "plt.show()\n",
    "\n",
    "best_SARIMA_fit.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# sarima_forcast = pd.DataFrame(sarima_forcast,index = data_val.index,columns=[\"Prediction\"])\n",
    "sarima_forcast = pd.Series(sarima_result.predict(n_periods=52), index=data_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we can see that though the SARIMA has higher RMSE and MAE than ARIMA, its Ljung-Box test and JB test has higher values, meaning the seasonal component is taken care.\n",
    "* let's compare the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mse = np.sqrt(mean_squared_error(np.exp(best_SARIMA_predictions),np.exp(test_X)))\n",
    "exp_mae = np.sqrt(mean_absolute_error(np.exp(best_SARIMA_predictions),np.exp(test_X)))\n",
    "print(f'{exp_mse}, {exp_mae}')\n",
    "\n",
    "compare = np.concatenate(((np.exp(best_SARIMA_predictions)),np.exp(test_X))).reshape(2,-1)\n",
    "compare = pd.DataFrame(compare).transpose()\n",
    "compare = compare.rename(columns={0:'prediction', 1:'bookings'})\n",
    "compare['residual'] = compare['prediction']/compare['bookings']\n",
    "plt.figure()\n",
    "plt.hist(compare['residual'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_rate = compare[(compare['residual'] >=0.80) & (compare['residual'] <=1.20)].shape[0]/compare.shape[0]\n",
    "agg_residual_rate = np.mean(compare['residual'].values)\n",
    "\n",
    "print(f'the residual that is lower than 20% is {residual_rate}, the average residual is {agg_residual_rate}.')\n",
    "compare[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* as we have the best orders, and the training will only take one minutes, it's not necessary to save the models."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import joblib\n",
    "# Pickle it\n",
    "joblib.dump(best_ARIMA, \"./model/best_baseline_ARIMA.pkl\")\n",
    "joblib.dump(sarima_result, \"./model/best_SARIMA.pkl\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# load models\n",
    "filename = \"./model/best_baseline_ARIMA.pkl\"\n",
    "loaded_model = joblib.load(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c690e20ef665247e3fc41fa4f53044a82e953ab60a82c44b04049d6d4ffcc0db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
