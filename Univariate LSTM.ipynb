{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.models import load_model\n",
    "from keras import callbacks, regularizers, optimizers\n",
    "from keras.regularizers import L1L2\n",
    "from keras_tuner import RandomSearch, Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN IT: define a function check_stationarity(series)\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series):\n",
    "\n",
    "    result = adfuller(series.values)\n",
    "\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n",
    "        print(\"\\u001b[32mStationary\\u001b[0m\")\n",
    "    else:\n",
    "        print(\"\\x1b[31mNon-stationary\\x1b[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links\n",
    "* https://towardsdatascience.com/breaking-the-curse-of-small-data-sets-in-machine-learning-part-2-894aa45277f4* \n",
    "* cross validation: https://github.com/Saktan/RNN-LSTM-with-Cross-Validation-for-Bitcoin-Price-Prediction/blob/master/Major_pro_final_1.ipynb\n",
    "* https://www.sciencedirect.com/science/article/abs/pii/S0925231218311639: the preprocessing includes the decrease the noise but according to this http://cs230.stanford.edu/projects_fall_2021/reports/102851552.pdf, noise can be useful. So I will not remove the noise.\n",
    "* the use of time series generator in here: https://medium.com/@cdabakoglu/time-series-forecasting-arima-lstm-prophet-with-python-e73a750a9887. But the design is not well-designed.\n",
    "* https://www.kaggle.com/code/amar09/lstm-for-univariate-ts-forecasting\n",
    "* Comparison of ARIMA and LSTM on univariate feature: https://acikerisim.sakarya.edu.tr/bitstream/handle/20.500.12619/45547/10.3846jbem.2019.10190.pdf?sequence=1&isAllowed=y\n",
    "* LSTM is worse than ARIMA: https://thesis.eur.nl/pub/53546/Cracan_Thesis.pdf\n",
    "* Above two shows that the ARIMA-LSTM hybrid model is the best\n",
    "* The setting of recurrent dropout layer: https://stackoverflow.com/questions/44924690/keras-the-difference-between-lstm-dropout-and-lstm-recurrent-dropout the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the original weekly sum\n",
    "series = pd.read_csv('./data/weekly_sum.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "data = pd.DataFrame(series.values, index=range(0,312))\n",
    "data.columns = ['bookings']\n",
    "data['bookings'] = np.log(data['bookings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data after log transformation\n",
    "series = pd.read_csv('./data/preprocessed_data.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "data = pd.DataFrame(series.values, index=range(0,312))\n",
    "data.columns = ['bookings']\n",
    "\n",
    "test_size = 52\n",
    "data_train, data_test =  data[ :-test_size], data[-test_size:]\n",
    "\n",
    "print( data_train.shape, data_test.shape)\n",
    "check_stationarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data into the problem scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(data_train)\n",
    "scaled_train_data = scaler.transform(data_train)\n",
    "scaled_test_data = scaler.transform(data_test)\n",
    "scaled_data = np.append(scaled_train_data, scaled_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data into supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only generate on scaled train data. The test date will use the 5th year scaled values as X.\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "def data_generator(data, n_input, n_features):\n",
    "    generator = TimeseriesGenerator(data = data, targets= data, length=n_input, batch_size=1)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse versions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# give up, just use the not differencing version. It's impossible to inverse the differencing from predictions\n",
    "\n",
    "def diff_inv(series_diff, first_value):\n",
    "    series_inverted = np.r_[first_value,series_diff].cumsum().astype('float64')\n",
    "    return series_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to report performance\n",
    "def lstm_report(y_true, y_pred):\n",
    "    # measures on validation set\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return rmse, mse, mae, mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hyperparameters:\n",
    "* the length of the feature. 1, 13, 52. - choose the best\n",
    "* the architecture: the neuron numbers, the hidden layer numbers, dropout layers, etc. Save the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-defined functions of building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = data_generator(scaled_train_data, 13, 1)\n",
    "d_test = data_generator(np.append(scaled_train_data[-52:], scaled_test_data), 13, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vanilla(n_input, neuron):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(neuron, activation='relu', input_shape=(n_input, 1)))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def create_callbacks():\n",
    "  early_stopping = EarlyStopping(patience=5, monitor='loss', verbose=1)\n",
    "  reduce_lr = ReduceLROnPlateau(monitor='loss', min_lr=0.001, patience=5, mode='min', verbose=1)\n",
    "  model_checkpoint = ModelCheckpoint(monitor='loss', filepath='./model/lstm.h5', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "  callbacks = [\n",
    "      early_stopping,\n",
    "      reduce_lr,\n",
    "      model_checkpoint\n",
    "  ]\n",
    "\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that there is a 'scaled_data' variable, it's specified.\n",
    "# the orignal version uses the predicted value as the feature to predict\n",
    "# I use the walking forward validation\n",
    "def predict_lstm(n_input, model, test_data):\n",
    "    lstm_predictions_scaled = list()\n",
    "\n",
    "    for i in range(len(test_data)): \n",
    "        batch = scaled_data[-52-n_input:-1][i:i+n_input]\n",
    "        current_batch = batch.reshape((1, n_input, 1))  \n",
    "        lstm_pred = model.predict(current_batch, verbose=0)[0]\n",
    "        lstm_predictions_scaled.append(lstm_pred) \n",
    "        current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
    "    lstm_predictions = pd.Series(lstm_predictions.reshape(1,52)[0], index=data_test.index)\n",
    "    return lstm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hy0: the validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old method to test vanilla\n",
    "# which is to use the newly predicted value to predict new value, rather than use the real data\n",
    "\n",
    "\n",
    "def predict_lstm0(n_input, model, test_data):\n",
    "    lstm_predictions_scaled = list()\n",
    "    batch = scaled_train_data[-n_input:]\n",
    "    current_batch = batch.reshape((1, n_input, 1))  \n",
    "\n",
    "    for i in range(len(test_data)): \n",
    "        lstm_pred = model.predict(current_batch, verbose=0)[0]\n",
    "        lstm_predictions_scaled.append(lstm_pred) \n",
    "        current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
    "    lstm_predictions = pd.Series(lstm_predictions.reshape(1,52)[0], index=data_test.index)\n",
    "    return lstm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_lstm0(13, vanilla, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Vanilla LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = pd.DataFrame(columns=['rmse', 'mse', 'mae', 'mape'])\n",
    "\n",
    "model_selection.loc['Vanilla LSTM, Classical Prediction'] = \\\n",
    "                    list(lstm_report(data_test, \n",
    "                         predict_lstm0(13, vanilla, data_test)))\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp1: input size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* let's check the first hyperparamer, the length of the input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models for different input sizes: 1, 13, 52\n",
    "vanilla_1 = create_vanilla(1, 512)\n",
    "vanilla_2 = create_vanilla(13, 512)\n",
    "vanilla_3 = create_vanilla(52, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_1.fit(data_generator(scaled_train_data, 1, 1),epochs=20)\n",
    "vanilla_2.fit(data_generator(scaled_train_data, 13, 1),epochs=20)\n",
    "vanilla_3.fit(data_generator(scaled_train_data, 52, 1),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len_tune = pd.DataFrame(columns=['rmse', 'mse', 'mae', 'mape'])\n",
    "for i in ([1, vanilla_1], [13, vanilla_2], [52, vanilla_3]):\n",
    "        input_len_tune.loc[f\"vanilla LSTM, n_input = {str(i[0])}\"] = list(lstm_report(data_test, predict_lstm(i[0], i[1], data_test)))\n",
    "input_len_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "# from the plot, we can see when input length = 1 or 52, they are unable to capture the patterns.\n",
    "\n",
    "lstm_predictions = predict_lstm(1, vanilla_1, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Vanilla LSTM Predictions, input length = 1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "lstm_predictions = predict_lstm(13, vanilla_2, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Vanilla LSTM Predictions, input length = 13')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "lstm_predictions = predict_lstm(52, vanilla_3, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Vanilla LSTM Predictions, input length = 52')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "vanilla = create_vanilla(13, 512)\n",
    "vanilla.fit(d_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Vanilla LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(vanilla.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.loc['Vanilla LSTM'] = \\\n",
    "                    list(lstm_report(data_test, \n",
    "                         predict_lstm(13, vanilla, data_test)))\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_lstm(13, vanilla, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Vanilla LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "vanilla.save('./model/vanilla LSTM.h5')\n",
    "load_model('./model/vanilla LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hp2: architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* random search on: the number of neurons in each hidden layers. regularizers = l1l2 + dropoyt layer. The learning rate of the optimizer Adam\n",
    "* tuned hp: add more layers\n",
    "* The whole random search things doesn't work. I will just do it manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM 1, hidden layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla: unit = 512\n",
    "# Stack: hidden layer = 1, 2, 3\n",
    "# add dropout layer to stack2 model, because the performance decreases, might be overfitting.\n",
    "\n",
    "def create_2_stack(n_input, neuron1, neuron2):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(neuron1, activation='relu', input_shape=(n_input, 1), return_sequences=True))\n",
    "    lstm_model.add(LSTM(neuron2))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "stack1 = create_2_stack(13, 512, 512)\n",
    "stack1.fit(d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Stacked LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(stack1.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "lstm_predictions = predict_lstm(13, stack1, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Stacked LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.loc['Stack LSTM, 2 hidden layers'] = \\\n",
    "                    list(lstm_report(data_test, \n",
    "                         predict_lstm(13, stack1, data_test)))\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM, hidden layer = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3_stack(n_input, neuron1, neuron2, neuron3):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(neuron1, activation='relu', input_shape=(n_input, 1), return_sequences=True))\n",
    "    lstm_model.add(LSTM(neuron2, return_sequences=True))\n",
    "    lstm_model.add(LSTM(neuron3))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "stack2 = create_3_stack(13, 512, 512, 512)\n",
    "stack2.fit(d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Stacked LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(stack2.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "lstm_predictions = predict_lstm(13, stack2, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Stacked LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.loc['Stack LSTM, 3 hidden layers'] = \\\n",
    "                    list(lstm_report(data_test, \n",
    "                         predict_lstm(13, stack2, data_test)))\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked LSTM, hidden layer = 2, dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3_stack2(n_input, neuron1, neuron2, neuron3, dropout_rate):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(neuron1, activation='relu', input_shape=(n_input, 1), return_sequences=True))\n",
    "    lstm_model.add(LSTM(neuron2, return_sequences=True))\n",
    "    lstm_model.add(LSTM(neuron3, recurrent_dropout = dropout_rate, recurrent_regularizer=L1L2(l1=0.001, l2=0.001)))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "stack3 = create_3_stack2(13, 512, 512, 512, 0.1)\n",
    "stack3.fit(d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Stacked LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(stack3.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "lstm_predictions = predict_lstm(13, stack3, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Stacked LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection.loc['Stack LSTM, 3 hidden layers, dropout rate = 0.1'] = \\\n",
    "                    list(lstm_report(data_test, \n",
    "                         predict_lstm(13, stack3, data_test)))\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Expired] hp3: stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use the stationary data to compare with the result from the non-stationary data with same hyperparameters. But it's impossible to compare differenced predictions to ARIMA. There is no way to inverse the differencing of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data after log transformation\n",
    "series = pd.read_csv('./data/preprocessed_data.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "data = pd.DataFrame(series.values, index=range(0,312))\n",
    "data.columns = ['bookings']\n",
    "\n",
    "test_size = 52\n",
    "data_train, data_test =  data[ :-test_size], data[-test_size:]\n",
    "\n",
    "print( data_train.shape, data_test.shape)\n",
    "check_stationarity(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the diff_data index is from 1 to 311. It means it's from week 2 to week 312\n",
    "diff_series = data.squeeze().diff().dropna()\n",
    "diff_data = pd.DataFrame(diff_series.values, index=range(1,312))\n",
    "diff_data.columns = ['bookings']\n",
    "check_stationarity(diff_data)\n",
    "\n",
    "test_size = 52\n",
    "diff_data_train, diff_data_test =  diff_data[ :-test_size], diff_data[-test_size:]\n",
    "\n",
    "print(diff_data_train.shape, diff_data_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(diff_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "diff_scaler = MinMaxScaler()\n",
    "\n",
    "diff_scaler.fit(diff_data)\n",
    "diff_scaled_train_data = diff_scaler.transform(diff_data_train)\n",
    "diff_scaled_test_data = diff_scaler.transform(diff_data_test)\n",
    "diff_scaled_data = np.append(diff_scaled_train_data, diff_scaled_test_data)\n",
    "# only generate on scaled train data. The test date will use the 5th year scaled values as X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_d_train = data_generator(diff_scaled_train_data, 13, 1)\n",
    "diff_d_test = data_generator(diff_scaled_data, 13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best is stack model with 2 hidden layers\n",
    "\n",
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "diff_vanilla = create_vanilla(13, 512)\n",
    "diff_vanilla.fit(diff_d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Stacked LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(diff_vanilla.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "lstm_predictions = predict_lstm(13, diff_vanilla, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Vanilla LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hp 4: model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirectional(n_input, neuron):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Bidirectional(LSTM(neuron, activation=\"relu\", input_shape=(n_input, 1))))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "bidirectional = create_bidirectional(13, 512)\n",
    "bidirectional.fit(d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Biodirectional LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(bidirectional.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_lstm(13, bidirectional, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Bidirectional LSTM Predictions, input_length = 13')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_report(data_test, predict_lstm(13, bidirectional, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional.save('./model/bidirectional_r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BI-LSTM with multiple layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bidirectional(n_input, neuron):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Bidirectional(LSTM(neuron, activation=\"relu\", input_shape=(n_input, 1), return_sequences=True)))\n",
    "    lstm_model.add(Bidirectional(LSTM(neuron)))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "bidirectional2 = create_stacked_bidirectional(13, 512)\n",
    "bidirectional2.fit(d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Biodirectional LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(bidirectional2.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_lstm(13, bidirectional2, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Bidirectional LSTM Predictions, hidden layer = 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_report(data_test, predict_lstm(13, bidirectional2, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional2.save('./model/bidirectional_r2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BI-LSTM with multiple layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bidirectional2(n_input, neuron):\n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(Bidirectional(LSTM(neuron, activation=\"relu\", input_shape=(n_input, 1), return_sequences=True)))\n",
    "    lstm_model.add(Bidirectional(LSTM(neuron, return_sequences=True)))\n",
    "    lstm_model.add(Bidirectional(LSTM(neuron)))\n",
    "    lstm_model.add(Dense(1))\n",
    "    lstm_model.compile(optimizer='adam', loss=keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see n_input = 13 has the best performance as it captures the patterns. Let's plot the best model - our new baseline model\n",
    "bidirectional3 = create_stacked_bidirectional2(13, 512)\n",
    "bidirectional3.fit(d_train, epochs=20)\n",
    "plt.figure()\n",
    "plt.title('Loss History of Univariate Biodirectional LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(bidirectional3.history.history['loss'], label = \"loss\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_lstm(13, bidirectional3, data_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true')\n",
    "plt.plot(lstm_predictions, label = 'y_pred')\n",
    "plt.title('Univariate Bidirectional LSTM Predictions, hidden layer = 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_report(data_test, predict_lstm(13, bidirectional3, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirectional3.save('./model/bidirectional_r3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Performance change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predictions = predict_lstm(13, bidirectional, data_test)\n",
    "\n",
    "exp_mse = np.sqrt(mean_squared_error(np.exp(lstm_predictions),np.exp(data_test)))\n",
    "exp_mae = np.sqrt(mean_absolute_error(np.exp(lstm_predictions),np.exp(data_test)))\n",
    "print(f'{exp_mse}, {exp_mae}')\n",
    "\n",
    "compare = np.concatenate(((np.exp(lstm_predictions.values)),np.exp(data_test.values).reshape(1,-1)[0])).reshape(2,-1)\n",
    "compare = pd.DataFrame(compare).transpose()\n",
    "compare = compare.rename(columns={0:'prediction', 1:'bookings'})\n",
    "compare['residual'] = compare['prediction']/compare['bookings']\n",
    "plt.figure()\n",
    "plt.hist(compare['residual'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_rate = compare[(compare['residual'] >=0.80) & (compare['residual'] <=1.20)].shape[0]/compare.shape[0]\n",
    "agg_residual_rate = np.mean(compare['residual'].values)\n",
    "print(f'the residual that is lower than 20% is {residual_rate}, the average residual is {agg_residual_rate}.')\n",
    "compare[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "vanilla.save('./model/univariate_vanilla.h5')\n",
    "stack1.save('./model/univariate_stack1.h5')\n",
    "stack2.save('./model/univariate_stack2.h5')\n",
    "stack3.save('./model/univariate_stack3.h5')\n",
    "bidirectional.save('./model/bidirectional.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not Work"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# define a model for random search\n",
    "# just add one more layer as we don't have enough data\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('input_unit',min_value=32,max_value=512,step=32), \n",
    "                   return_sequences=True, input_shape=(13, 1),\n",
    "                   recurrent_dropout = hp.Float('Dropout_rate1',min_value=0,max_value=0.5,step=0.1),\n",
    "                   bias_regularizer=L1L2(l1= hp.Choice('l1_1', [0.00, 0.01]), l2=hp.Choice('l2_1', [0.00, 0.01]))))\n",
    "    model.add(LSTM(hp.Int('layer_2_neurons',min_value=32,max_value=512,step=32),\n",
    "                   recurrent_dropout = hp.Float('Dropout_rate2',min_value=0,max_value=0.5,step=0.1),\n",
    "                   bias_regularizer=L1L2(l1= hp.Choice('l1_2', [0.00, 0.01]), l2=hp.Choice('l2_2', [0.00, 0.01]))))\n",
    "    model.add(Dense(1))\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model.compile(optimizer= optimizers.Adam(learning_rate=hp_lr), loss = keras.losses.MeanSquaredError(), metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner =  RandomSearch(hypermodel=build_model,\n",
    "                      objective=Objective(name=\"mse\",direction=\"min\"),\n",
    "                      max_trials=5,\n",
    "                      seed=10,\n",
    "                      overwrite=True)\n",
    "tuner.search(data_generator(scaled_train_data, 13, 1), epochs=20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_hps.get_config()['values']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tuned_model = tuner.hypermodel.build(best_hps)\n",
    "tuned_model.fit(data_generator(scaled_train_data, 13, 1) ,epochs=20, callbacks=create_callbacks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# save model\n",
    "tuned_model.save('./model/Stacked LSTM.h5')\n",
    "load_model('./model/Stacked LSTM.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "losses_lstm = tuned_model.history.history['mse']\n",
    "plt.figure()\n",
    "plt.title('Loss History of Stacked LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(len(losses_lstm)),losses_lstm, label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "losses_lstm = tuned_model.history.history['loss']\n",
    "plt.figure()\n",
    "plt.title('Loss History of Stacked LSTM')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(range(len(losses_lstm)),losses_lstm, label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# model_selection = pd.DataFrame(columns=['rmse', 'mse', 'mae', 'mape'])\n",
    "\n",
    "model_selection.loc['Stacked Vanilla LSTM'] = \\\n",
    "                    list(lstm_report(data_test, \n",
    "                         predict_lstm(13, tuned_model, data_test)))\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(predict_lstm(13, tuned_model, data_test), label ='y_pred')\n",
    "plt.title('Stacked LSTM Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(data_test, label = 'y_true', color = 'C1')\n",
    "plt.title('Stacked LSTM True Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c690e20ef665247e3fc41fa4f53044a82e953ab60a82c44b04049d6d4ffcc0db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
