{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.models import load_model\n",
    "from keras import callbacks, regularizers, optimizers\n",
    "from keras.regularizers import L1L2\n",
    "from keras_tuner import RandomSearch, Objective\n",
    "import scipy\n",
    "import feature_engine\n",
    "import pmdarima\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR, ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/preprocessed_data.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "test_size = 52\n",
    "data_train, data_val, data_test = data[ :-2*test_size], data[-2*test_size:-test_size], data[-test_size:]\n",
    "data_train_val, data_test = data[ :-test_size], data[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = data_train.values\n",
    "val_X  = data_val.values\n",
    "test_X = data_test.values\n",
    "train_val_X = data_train_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AM_model = AutoReg(train_val_X, lags=13)\n",
    "AM_model_fit = AM_model.fit()\n",
    "AM_predictions = AM_model_fit.predict(start=len(train_val_X), end=len(train_val_X)+len(test_X)-1, dynamic=False)\n",
    "AM_predictions = pd.Series(AM_predictions, index=data_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = pd.DataFrame(data_test)\n",
    "final_differences = pd.DataFrame(data_test)\n",
    "def add_pred(series, name):\n",
    "    final_predictions[name] = series\n",
    "    return final_predictions\n",
    "def cal_diff(series, name):\n",
    "    final_differences[name+\"_diff\"] = data_test - series\n",
    "    return final_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(AM_predictions, 'AM_predictions')\n",
    "cal_diff(AM_predictions, 'AM_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "best_cfg = (13, 1, 0)\n",
    "best_ARIMA = ARIMA(train_val_X, order = best_cfg)\n",
    "best_ARIMA_fit = best_ARIMA.fit()\n",
    "best_ARIMA_predictions = pd.Series(best_ARIMA_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_ARIMA_predictions = best_ARIMA_predictions.set_axis(data_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(best_ARIMA_predictions, 'best_ARIMA_predictions')\n",
    "cal_diff(best_ARIMA_predictions, 'best_ARIMA_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "best_cfg = np.array(['(3, 1, 2)', '(3, 0, 0, 52)'], dtype='<U16')\n",
    "best_SARIMA = SARIMAX(endog = train_val_X, order = eval(best_cfg[0]), seasonal_order = eval(best_cfg[1]))\n",
    "best_SARIMA_fit = best_SARIMA.fit()\n",
    "best_SARIMA_predictions = pd.Series(best_SARIMA_fit.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_SARIMA_predictions = best_SARIMA_predictions.set_axis(data_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(best_SARIMA_predictions, 'sarima1')\n",
    "cal_diff(best_SARIMA_predictions, 'sarima1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cfg = np.array(['(2, 1, 1)', '(2, 0, 0, 52)'], dtype='<U16')\n",
    "best_SARIMA2 = SARIMAX(endog = train_val_X, order = eval(best_cfg[0]), seasonal_order = eval(best_cfg[1]))\n",
    "best_SARIMA_fit2 = best_SARIMA2.fit()\n",
    "best_SARIMA_predictions2 = pd.Series(best_SARIMA_fit2.predict(start = len(train_val_X), end=len(train_val_X)+ len(test_X)-1, dynamic = False))\n",
    "best_SARIMA_predictions2 = best_SARIMA_predictions2.set_axis(data_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(best_SARIMA_predictions2, 'sarima2')\n",
    "cal_diff(best_SARIMA_predictions2, 'sarima2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data after log transformation\n",
    "series = pd.read_csv('./data/preprocessed_data.csv', index_col=0, parse_dates=True, squeeze=True)\n",
    "data = pd.DataFrame(series.values, index=range(0,312))\n",
    "data.columns = ['bookings']\n",
    "\n",
    "test_size = 52\n",
    "data_train, data_test =  data[ :-test_size], data[-test_size:]\n",
    "\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "def data_generator(data, n_input, n_features):\n",
    "    generator = TimeseriesGenerator(data = data, targets= data, length=n_input, batch_size=1)\n",
    "    return generator\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(data_train)\n",
    "scaled_train_data = scaler.transform(data_train)\n",
    "scaled_test_data = scaler.transform(data_test)\n",
    "scaled_data = np.append(scaled_train_data, scaled_test_data)\n",
    "\n",
    "d_train = data_generator(scaled_train_data, 13, 1)\n",
    "d_test = data_generator(np.append(scaled_train_data[-52:], scaled_test_data), 13, 1)\n",
    "\n",
    "def predict_lstm(n_input, model, test_data):\n",
    "    lstm_predictions_scaled = list()\n",
    "\n",
    "    for i in range(len(test_data)): \n",
    "        batch = scaled_data[-52-n_input:-1][i:i+n_input]\n",
    "        current_batch = batch.reshape((1, n_input, 1))  \n",
    "        lstm_pred = model.predict(current_batch, verbose=0)[0]\n",
    "        lstm_predictions_scaled.append(lstm_pred) \n",
    "        current_batch = np.append(current_batch[:,1:,:],[[lstm_pred]],axis=1)\n",
    "    lstm_predictions = scaler.inverse_transform(lstm_predictions_scaled)\n",
    "    lstm_predictions = pd.Series(lstm_predictions.reshape(1,52)[0], index=data_test.index)\n",
    "    return lstm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_diff_lstm(series, name):\n",
    "    final_differences[name+\"_diff\"] =  data_test.to_numpy().reshape(1,-1)[0] - np.array(series)\n",
    "    return final_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_lstm = load_model('./model/univariate_stack1.h5')\n",
    "uni_lstm_prediction = predict_lstm(13, uni_lstm, data_test)\n",
    "uni_lstm_prediction = np.array(uni_lstm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(uni_lstm_prediction, 'uni_lstm')\n",
    "cal_diff_lstm(uni_lstm_prediction, 'uni_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_bi_lstm = load_model('./model/bidirectional_r')\n",
    "uni_bi_lstm_prediction = predict_lstm(13, uni_bi_lstm, data_test)\n",
    "uni_bi_lstm_prediction = np.array(uni_bi_lstm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(uni_bi_lstm_prediction, 'uni_bi_lstm')\n",
    "cal_diff_lstm(uni_bi_lstm_prediction, 'uni_bi_lstm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multivariate LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_sum = pd.read_csv('./data/area sum.csv', index_col=0, parse_dates=True).squeeze(\"columns\")\n",
    "\n",
    "test_size = 52\n",
    "data_train, data_test =  area_sum.iloc[ :-test_size,:], area_sum.iloc[-test_size:,:]\n",
    "\n",
    "# log transformation\n",
    "data_train, data_test = np.log(data_train+1), np.log(data_test+1)\n",
    "\n",
    "# split the dataset for normalization\n",
    "train_X = data_train.iloc[:,:-1]\n",
    "train_y = np.array(data_train.iloc[:,-1]).reshape(-1,1)\n",
    "test_X = data_test.iloc[:,:-1]\n",
    "test_y = np.array(data_test.iloc[:,-1]).reshape(-1,1)\n",
    "\n",
    "# normalization\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "scaler_X.fit(train_X)\n",
    "scaled_train_X = scaler_X.transform(train_X)\n",
    "scaled_test_X = scaler_X.transform(test_X)\n",
    "\n",
    "scaler_y.fit(train_y)\n",
    "scaled_train_y = scaler_y.transform(train_y)\n",
    "scaled_test_y = scaler_y.transform(test_y)\n",
    "\n",
    "scaled_X = np.append(scaled_train_X, scaled_test_X, axis=0)\n",
    "\n",
    "print(scaled_train_X.shape, scaled_test_X.shape, scaled_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walking forward validation\n",
    "def predict_lstm(n_input, n_feature, model, data_test, data):\n",
    "    lstm_predictions_scaled = list()\n",
    "\n",
    "    for i in range(data_test.shape[0]): \n",
    "        batch = data[-52-n_input:-1, :][i:i+n_input, :]\n",
    "        current_batch = batch.reshape((1, n_input, n_feature))\n",
    "        lstm_pred = model.predict(current_batch, verbose=0)[0]\n",
    "        lstm_predictions_scaled.append(lstm_pred)\n",
    "    lstm_predictions = scaler_y.inverse_transform(lstm_predictions_scaled)\n",
    "    lstm_predictions = pd.Series(lstm_predictions.reshape(1,52)[0], index=data_test.index)\n",
    "    return lstm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lstm = load_model('./model/vanilla_area.h5')\n",
    "multi_lstm_prediction = predict_lstm(13, 9, multi_lstm, data_test, scaled_X)\n",
    "multi_lstm_prediction = np.array(multi_lstm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_diff_lstm_multi(series, name):\n",
    "    final_differences[name+\"_diff\"] =  data_test['All'].to_numpy().reshape(1,-1)[0] - np.array(series)\n",
    "    return final_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(multi_lstm_prediction, 'multi_lstm')\n",
    "cal_diff_lstm_multi(multi_lstm_prediction, 'multi_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_bi_lstm = load_model('./model/bidirectional_area')\n",
    "multi_bi_lstm_prediction = predict_lstm(13, 9, multi_bi_lstm, data_test, scaled_X)\n",
    "multi_bi_lstm_prediction = np.array(multi_bi_lstm_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pred(multi_bi_lstm_prediction, 'multi__bi_lstm')\n",
    "cal_diff_lstm_multi(multi_bi_lstm_prediction, 'multi_bi_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_difference2 = final_differences.iloc[:,1:]\n",
    "final_difference2.columns = ['AM', 'ARIMA', 'SARIMA1', 'SARIMA2', 'Univariate LSTM', 'Univariate BI-LSTM', 'Multivariate LSTM', 'Multivariate BI-LSTM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(final_difference2, lw=1.5)\n",
    "plt.legend(final_difference2.columns, bbox_to_anchor=(1, 1.05))\n",
    "plt.xticks(np.arange(260, 312, step=2))\n",
    "plt.axhline(y=0, color='purple', ls='--', lw=1)\n",
    "plt.vlines([260, 273, 286, 299, 311], ymin=final_difference2.min().min(), ymax= final_difference2.max().max(), colors='blue', ls='--', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(final_difference2.iloc[:,[0,1]], lw=1.5)\n",
    "plt.legend(['AM','ARIMA'])\n",
    "plt.xticks(np.arange(260, 312, step=2))\n",
    "plt.axhline(y=0, color='purple', ls='--', lw=1)\n",
    "plt.vlines([260, 273, 286, 299, 311], ymin=final_difference2.min().min(), ymax= final_difference2.max().max(), colors='blue', ls='--', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(final_difference2.iloc[:,[1,2,3]], lw=1.5)\n",
    "plt.legend(['ARIMA','SARIMA1', 'SARIMA2'])\n",
    "plt.xticks(np.arange(260, 312, step=2))\n",
    "plt.axhline(y=0, color='purple', ls='--', lw=1)\n",
    "plt.vlines([260, 273, 286, 299, 311], ymin=final_difference2.min().min(), ymax= final_difference2.max().max(), colors='blue', ls='--', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(final_difference2.iloc[:,[4,5]], lw=1.5)\n",
    "plt.legend(['Univariate LSTM', 'Univariate BI-LSTM'])\n",
    "plt.xticks(np.arange(260, 312, step=2))\n",
    "plt.axhline(y=0, color='purple', ls='--', lw=1)\n",
    "plt.vlines([260, 273, 286, 299, 311], ymin=final_difference2.min().min(), ymax= final_difference2.max().max(), colors='blue', ls='--', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(final_difference2.iloc[:,[6,7]], lw=1.5)\n",
    "plt.legend(['Multivariate LSTM', 'Multivariate BI-LSTM'])\n",
    "plt.xticks(np.arange(260, 312, step=2))\n",
    "plt.axhline(y=0, color='purple', ls='--', lw=1)\n",
    "plt.vlines([260, 273, 286, 299, 311], ymin=final_difference2.min().min(), ymax= final_difference2.max().max(), colors='blue', ls='--', lw=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 3))\n",
    "plt.plot(final_difference2.iloc[:,[2,5,7]], lw=1.5)\n",
    "plt.legend(['SARIMA1', 'Univariate LSTM', 'Multivariate BI-LSTM'])\n",
    "plt.xticks(np.arange(260, 312, step=2))\n",
    "plt.axhline(y=0, color='purple', ls='--', lw=1)\n",
    "plt.vlines([260, 273, 286, 299, 311], ymin=final_difference2.min().min(), ymax= final_difference2.max().max(), colors='blue', ls='--', lw=1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c690e20ef665247e3fc41fa4f53044a82e953ab60a82c44b04049d6d4ffcc0db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
